---
title: "GRAAL : Graph-based Research with Agents for Automatic Labelling"
subtitle: "Classification automatique dans des nomenclatures statistiques par approche agentique"
author:
  - name: Meilame Tayebjee
    email: meilame.tayebjee@insee.fr
    affiliations:
      - name: Insee, SSP Lab
  - name: Th√©o Ferry
    email: theo.ferry@insee.fr
    affiliations:
      - name: Insee, SSP Lab 
date: "04/02/2026"
date-format: "D MMMM YYYY"
slide-number: true
# uncomment for French presentations:
# lang: fr-FR
# for blind readers:
slide-tone: false
chalkboard: # press the B key to toggle chalkboard
  theme: whiteboard
# uncomment to use the multiplex mode:
# multiplex: true
format:
  onyxia-revealjs:
    output-file: index.html
controls: true
ascii: true
---

## Plan


1. **Contexte**. D√©fis de la codification automatique
2. **Le framework GRAAL**. Architecture multi-agents
3. **Perspectives**. D√©veloppements futurs


# 1Ô∏è‚É£ **Contexte**: le cas d'usage de la codification automatique

##

- **NAF** : Nomenclature statistique des Activit√©s √©conomiques (NAF)
    - ~700 codes finaux
    - Structure hi√©rarchique sur 5 niveaux
  
- **COICOP** : *Classification of Individual Consumption by Purpose*
    - ~300 √† ~1000 selon la granularit√© employ√©e
    - Structure hi√©rarchique sur 5 niveaux

----
```{mermaid}
graph TD
  %% Sections
  S_A["Section A<br/>Agriculture, sylviculture et p√™che"]
  S_C["Section C<br/>Industrie manufacturi√®re"]

  %% Divisions
  D_01["Division 01<br/>Culture et production animale"]
  D_10["Division 10<br/>Industries alimentaires"]

  %% Groupes
  G_01_1["Groupe 01.1<br/>Cultures non permanentes"]
  G_10_1["Groupe 10.1<br/>Transformation et conservation de la viande"]

  %% Classes
  C_01_11["Classe 01.11<br/>Culture de c√©r√©ales"]
  C_10_11["Classe 10.11<br/>Transformation de la viande"]

  %% Relations
  S_A --> D_01
  S_C --> D_10

  D_01 --> G_01_1
  D_10 --> G_10_1

  G_01_1 --> C_01_11
  G_10_1 --> C_10_11
```

## D√©fis

- A l'heure actuelle, apprentissage supervis√© classique, avec des mod√®les de *deep learning* (PyTorch)
  - Frugal, performant et rapide, *production-ready*... üòé 
  - ... mais n√©cessite entre 100k et 1M de donn√©es labellis√©es ü´®


## Une approche MLOps grandement facilit√©e par Onyxia mais encore incompl√®te {.scrollable}

:::{.incremental}
- **Data** : Stockage S3 (Datalab), versionnage avec MLFlow Datasets ‚úÖ
- **Mod√®le** : d√©veloppement internalis√© et distribution de l‚Äôarchitecture via le package  
  [*torchTextClassifiers*](https://github.com/InseeFrLab/torchTextClassifiers), entra√Ænement parall√©lis√© avec Argo Workflows, model storage avec MLFlow ‚úÖ
- **D√©ploiement** : FastAPI d√©ploy√© via conteneurisation (Docker) ‚úÖ
- **Monitoring** : c‚Äôest l√† que le b√¢t blesse ‚ùå  
  - Investissements humains n√©cessaires, pas toujours faits
  - **Comment contr√¥ler le mod√®le en production sans annotation humaine continue ?**
:::

## Le besoin de s'affranchir des donn√©es labellis√©es {.scrollable}

:::{.incremental}
- Comment faire quand on ne peut pas avoir / n'a pas assez de donn√©es labellis√©es ?
- Comment faire quand la nomenclature est mise √† jour par le m√©tier ?
  - Il faut recoder les donn√©es existantes
- Comment faire quand nos donn√©es labellis√©es ne sont pas fiables ?
   - et qu'id√©alement on veuille les corriger...
:::

---

:::{.incremental}
- Une premi√®re approche **zero-shot** : [**le Retrieval-Augmented Generation (RAG)**]{.orange}
    - Knowledge base = les notices officielles pour chaque code
    - Tr√®s bonne premi√®re solution mais...
      - d√©pendance au chunking...
      - d√©pendance au mod√®le d'embedding...
      - saturation du contexte avec les notices...
      - on compare embedding de *notice* √† un embedding de *libell√©*...
      - pas de tra√ßabilit√©, pas de raisonnement...
      - pas de prise en compte de la hi√©rarchie !
:::

## Objectifs

- On ne veut plus d'embeddings
- On veut du *reasoning*: le LLM peut/doit justifier ses choix (*chain of thought*)
  - Plut√¥t que lui *imposer du contexte* comme dans un RAG, laisser le mod√®le **compl√©ter son contexte dynamiquement** ([**= agent !**]{.orange})
  - Id√©alement, avec un raisonnement autour de la hi√©rarchie

# 2Ô∏è‚É£ **Le framework GRAAL** 

## Neo4j : une *graph database* {.scrollable}
```{mermaid}
graph TD
  ROOT["Root"]

  %% Sections
  J["CODE: J<br/>LEVEL: 1"]
  A["CODE: A<br/>LEVEL: 1"]

  %% Divisions
  J60["CODE: J60<br/>LEVEL: 2"]
  J61["CODE: J61<br/>LEVEL: 2"]
  A01["CODE: A01<br/>LEVEL: 2"]

  %% Groupes
  J60_1["CODE: J60.1<br/>LEVEL: 3"]
  J60_2["CODE: J60.2<br/>LEVEL: 3"]
  A01_1["CODE: A01.1<br/>LEVEL: 3"]

  %% Classes
  J60_11["CODE: J60.11<br/>LEVEL: 4"]
  J60_12["CODE: J60.12<br/>LEVEL: 4"]
  A01_11["CODE: A01.11<br/>LEVEL: 4"]

  %% Relations HAS_PARENT
  J -->|HAS_PARENT| ROOT
  A -->|HAS_PARENT| ROOT

  J60 -->|HAS_PARENT| J
  J61 -->|HAS_PARENT| J
  A01 -->|HAS_PARENT| A

  J60_1 -->|HAS_PARENT| J60
  J60_2 -->|HAS_PARENT| J60
  A01_1 -->|HAS_PARENT| A01

  J60_11 -->|HAS_PARENT| J60_1
  J60_12 -->|HAS_PARENT| J60_1
  A01_11 -->|HAS_PARENT| A01_1
```

## Utilisation du graph comme support pour des agents


- On d√©finit un ensemble d'outils **commun √† tous les agents**: 
    - get_code_information
    - get_children
    - get_descendants 
    - get_siblings
    - etc.

- Ils utilisent tous la syntaxe Neo4j

## Les agents {.scrollable}

- Un agent = un prompt, un type d'input et d'output, et des tools
- Les *closers*
  - *CodeChooser*: 
  - *MatchVerifier*:

    ```{python}
    #| echo: true
    #| code-fold: true
    #| eval: false

    class MatchVerifier(BaseAgent):
        def __init__(self, graph: Graph):
            super().__init__(graph)

        def get_agent_name(self) -> str:
            return "MatchVerifier Agent"

        def get_instructions(self) -> str:
            return """
                    Tu es un agent sp√©cialis√© dans la v√©rification de la validit√© d'une correspondance entre un libell√© textuel et le code qui lui a √©t√© associ√©. Tu as acc√®s √† des outils pour interroger une base de donn√©es de nomenclature statistique structur√©e en graph database Neo4j.
                """

        def get_output_type(self):
            return MatchVerificationResult

        def build_prompt(self, match_verification_input: MatchVerificationInput) -> str:
            """
            Construire le prompt pour l'agent de v√©rification de correspondance.
            """
            prompt = f"""
            V√©rifie si le code suivant correspond bien √† l'activit√© d√©crite.

            Activit√© : {match_verification_input.activity}

            Code propos√© : {match_verification_input.code}
            Explication propos√©e : {match_verification_input.proposed_explanation}

            R√©ponds en fournissant :
            1. Un bool√©en indiquant si la correspondance est valide.
            2. Un niveau de confiance entre 0 et 1.
            3. Une explication concise de ta d√©cision.
            """
            return prompt
    ```


- *Text2Code* (classifieur)
  - le *Navigator* est un agent qui h√©rite de *Text2Code*
- *Code2Text* (g√©n√©rateur de donn√©es synth√©tiques)


## Exemple de classification par *Navigator*

::: {.panel-tabset}

### Input
```python
description = """
Entreprise de fabrication artisanale de pains sp√©ciaux 
et viennoiseries, avec vente directe en boutique
"""
```

### Output
```json
{
  "code": "10.71Z",
  "label": "Fabrication de pain et p√¢tisserie fra√Æche",
  "confidence": 0.94,
  "path": ["C", "10", "10.7", "10.71", "10.71Z"],
  "justification": "Fabrication artisanale (C) de produits 
                    de boulangerie (10.7) avec vente directe : ce code correspond donc au libell√© fourni."
}
```
:::


## Evaluation {.scrollable}

:::{.incremental}
- **Evaluer un agent classifieur**
  - Si on fait confiance √† notre dataset de test : √©valuation straightforward
  - **Sinon : √©valuation manuelle !**
    - Pr√©diction *ground truth*, pr√©diction du classifieur, jugement du *CodeChooser* et du *MatchVerifier* mis bout √† bout
    - Evaluation conjointe de tous les composants
- **Evaluer la g√©n√©ration de donn√©es synth√©tiques**
  - moins √©vident
  - r√©entra√Æner un mod√®le sur un dataset synth√©tique et voir si on atteint des perfs √©quivalentes sur le m√™me test set
:::

## Perspectives

- Un cahier des charges respect√©
  - Plus *d'embeddings*
  - Du raisonnement et de la tra√ßabilit√©
  - **Utilisable pour n'importe quelle nomenclature** : il suffit de cr√©er une base Neo4j avec les notices et tout fonctionne !
    - GRAAL n'est qu'un distributeurs de tools, de prompts et de structures d'appels au LLM (validation input/output)
- **La t√¢che principale va √™tre l'√©valuation** üéØ

--- 

- **On va en faire quoi ?**
  - Un mod√®le agentique est trop lourd pour la production (pas encore de GPU, temps d'inf√©rence trop √©lev√©...)
  - Cependant, GRAAL peut √™tre utilis√© pour:
    - **Monitoring du mod√®le d√©ploy√©: *MatchVerifier* analyse les logs de l'API et √©value le mod√®le en continu, appelle le *Navigator* si besoin de recoder...**
    - Recodage d'une base (m√™me workflow que le monitoring)
    - G√©n√©ration de donn√©es synth√©tiques (*Code2Text*)


##  Merci de votre attention !
üîó [github.com/InseeFrLab/GRAAL](https://github.com/InseeFrLab/GRAAL)